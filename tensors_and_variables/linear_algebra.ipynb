{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSAMIjVUQDCj1seqoajuQl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhabinazmat21/Deep_Learning/blob/main/tensors_and_variables/linear_algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GMCnRD8PhWbl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = tf.constant([\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ],\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ],\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ],\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ]\n",
        "], dtype = tf.float32)\n",
        "\n",
        "x2 = tf.constant([\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ],\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ],\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ],\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ]\n",
        "], dtype = tf.float32)\n",
        "\n",
        "print(tf.linalg.matmul(x2,x1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MKYZMMdhhCX",
        "outputId": "f523461c-bc79-452b-d673-120b23e39eec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[  65. 1278. 6523.   64.]\n",
            "  [  86.  541. 2292.  281.]]\n",
            "\n",
            " [[  65. 1278. 6523.   64.]\n",
            "  [  86.  541. 2292.  281.]]\n",
            "\n",
            " [[  65. 1278. 6523.   64.]\n",
            "  [  86.  541. 2292.  281.]]\n",
            "\n",
            " [[  65. 1278. 6523.   64.]\n",
            "  [  86.  541. 2292.  281.]]], shape=(4, 2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = tf.constant([\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ],\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ],\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1],\n",
        "        [1,2,3,4],\n",
        "        [2,45,232,1]\n",
        "    ]\n",
        "])\n",
        "\n",
        "x4 = tf.constant([\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ],\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ],\n",
        "    [\n",
        "        [3,5,6,23],\n",
        "        [3,2,65,7]\n",
        "    ]\n",
        "])\n",
        "\n",
        "print(x4@x3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Wli6N8hkPU",
        "outputId": "94749605-3b69-4553-edae-e8ec2f9f5a21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[  65 1278 6523   64]\n",
            "  [  86  541 2292  281]]\n",
            "\n",
            " [[  65 1278 6523   64]\n",
            "  [  86  541 2292  281]]\n",
            "\n",
            " [[  65 1278 6523   64]\n",
            "  [  86  541 2292  281]]], shape=(3, 2, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1)\n",
        "print(tf.transpose(x1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXkFKJJRjkE2",
        "outputId": "0d29a4d4-dd2a-409f-86bd-4b2b59c2b322"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[  1   2   3   4]\n",
            "  [  2  45 232   1]\n",
            "  [  1   2   3   4]\n",
            "  [  2  45 232   1]]\n",
            "\n",
            " [[  1   2   3   4]\n",
            "  [  2  45 232   1]\n",
            "  [  1   2   3   4]\n",
            "  [  2  45 232   1]]\n",
            "\n",
            " [[  1   2   3   4]\n",
            "  [  2  45 232   1]\n",
            "  [  1   2   3   4]\n",
            "  [  2  45 232   1]]], shape=(3, 4, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[  1   1   1]\n",
            "  [  2   2   2]\n",
            "  [  1   1   1]\n",
            "  [  2   2   2]]\n",
            "\n",
            " [[  2   2   2]\n",
            "  [ 45  45  45]\n",
            "  [  2   2   2]\n",
            "  [ 45  45  45]]\n",
            "\n",
            " [[  3   3   3]\n",
            "  [232 232 232]\n",
            "  [  3   3   3]\n",
            "  [232 232 232]]\n",
            "\n",
            " [[  4   4   4]\n",
            "  [  1   1   1]\n",
            "  [  4   4   4]\n",
            "  [  1   1   1]]], shape=(4, 4, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Sparse matrices are a type of matrix in which most of the elements are zero. They are distinct from dense matrices, where most of the elements are non-zero. Sparse matrices are particularly useful in scenarios where large amounts of data are mostly zeros, as they allow for significant improvements in storage efficiency and computational performance.\n",
        "\n",
        "Why Use Sparse Matrices?\n",
        "Memory Efficiency: Storing only the non-zero elements of sparse matrices saves memory, which is beneficial when dealing with large datasets or matrices where the non-zero elements are few.\n",
        "Computational Efficiency: Operations such as multiplication or inversion can be faster on sparse matrices since calculations involving zero elements can be skipped.\n",
        "Representation of Sparse Matrices\n",
        "Sparse matrices can be represented in various formats, each optimizing different operations. Some common formats include:\n",
        "\n",
        "Compressed Sparse Row (CSR): Stores the non-zero values consecutively along with arrays for indices and row pointers. This format is efficient for row slicing and matrix-vector multiplication.\n",
        "Compressed Sparse Column (CSC): Similar to CSR but stores data column-wise. It is efficient for column slicing and other column-wise operations.\n",
        "Coordinate List (COO): Stores a list of (row, column, value) tuples. It is particularly useful for constructing sparse matrices incrementally as data can be added in any order.\n",
        "Applications of Sparse Matrices\n",
        "Sparse matrices are extensively used in various fields such as:\n",
        "\n",
        "Scientific Computing: In simulations and calculations involving large-scale systems, many of which have sparse characteristics.\n",
        "Machine Learning and Data Mining: In algorithms that involve large datasets, especially in natural language processing and recommendation systems.\n",
        "Graph Algorithms: In the representation of adjacency matrices for graphs, where most connections between nodes are absent (i.e., zero).\n",
        "Image Processing and Computer Vision: In scenarios involving image transformations where many values can be zero due to the nature of the transformation or filtering applied"
      ],
      "metadata": {
        "id": "0-FxQruRml1r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FDIKGsSpTRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}